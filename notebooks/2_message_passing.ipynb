{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message Passing\n",
    "\n",
    "In this notebook, we'll introduce the concept of Graph Convolution Neural Networks, specifically Message Passing Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [02:55:03] Enabling RDKit 2019.09.1 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "smiles = []\n",
    "with open('../data/01_raw/moses/dataset_v1.csv', 'r') as f:\n",
    "    _ = f.readline()\n",
    "    smiles = [f.readline().split(',')[0] for _ in range(120)]\n",
    "    f.close()\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions\n",
    "DrawingOptions.bondLineWidth=1.8\n",
    "\n",
    "import os,sys,inspect\n",
    "sys.path.insert(0,'/home/icarus/app/src') \n",
    "\n",
    "lg = RDLogger.logger()\n",
    "\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "import torch as torch\n",
    "#torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from structures.moltree import MolTree\n",
    "from structures.mol_features import N_ATOM_FEATS, N_BOND_FEATS\n",
    "mt = MolTree(smiles[0])\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(121)\n",
    "nx.draw(mt.to_networkx(), with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 97])\n",
      "torch.Size([40, 13])\n"
     ]
    }
   ],
   "source": [
    "graph, atom_features, bond_features = mt.encode(recssemble=True)\n",
    "print(atom_features.shape)\n",
    "print(bond_features.shape)\n",
    "\n",
    "del atom_features\n",
    "del bond_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph, mean_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loopy Belief Propagation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpn_loopy_bp_msg = fn.copy_src(src='msg', out='msg')\n",
    "mpn_loopy_bp_reduce = fn.sum(msg='msg', out='accum_msg')\n",
    "\n",
    "class LoopyBeliefProp_Update(nn.Module):\n",
    "    def __init__(self, hidden_size: int, args = None):\n",
    "        super(LoopyBeliefProp_Update, self).__init__()\n",
    "        self.device = args.device\n",
    "        self.use_cuda = args.use_cuda\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.W_h = nn.Linear(  # y = xA^T + b\n",
    "            in_features=hidden_size,\n",
    "            out_features=hidden_size,\n",
    "            bias=False\n",
    "        )\n",
    "        if self.use_cuda: self.W_h = self.W_h.cuda()\n",
    "    \n",
    "    def forward(self, nodes):\n",
    "        msg_input = nodes.data['msg_input']\n",
    "        accum_msg = nodes.data['accum_msg'].cuda() if self.use_cuda else nodes.data['accum_msg']\n",
    "        msg_delta = self.W_h(nodes.data['accum_msg'])\n",
    "        msg = F.relu(msg_input + msg_delta)\n",
    "        return {'msg': msg}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpn_gather_msg = fn.copy_edge(edge='msg', out='msg')\n",
    "mpn_gather_reduce = fn.sum(msg='msg', out='m')\n",
    "\n",
    "class MPN_Gather_Update(nn.Module):\n",
    "    def __init__(self, hidden_size: int, device=torch.device('cpu')):\n",
    "        super(MPN_Gather_Update, self).__init__()\n",
    "        self.device = args.device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_cuda = args.use_cuda\n",
    "        \n",
    "        self.W_o = nn.Linear(N_ATOM_FEATS + hidden_size, hidden_size)\n",
    "        if self.use_cuda: self.W_o = self.W_o.cuda()\n",
    "        \n",
    "    def forward(self, nodes):\n",
    "        m, x = nodes.data['m'], nodes.data['x']\n",
    "        if self.use_cuda: \n",
    "            m, x = m.cuda(), x.cuda()\n",
    "        h = F.relu(self.W_o(torch.cat([x, m], 1)))\n",
    "        if self.use_cuda: h = h.cuda()\n",
    "            \n",
    "        return {\n",
    "            'h': h\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jtnn_vae'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-378feb672b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphConvNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/app/src/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjtnn_vae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jtnn_vae'"
     ]
    }
   ],
   "source": [
    "from models.modules import GraphConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from structures import Vocab\n",
    "from typing import List, Tuple\n",
    "\n",
    "from utils.data import JTNNCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import structures\n",
    "import structures.mol_features as mf\n",
    "import torch as torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import JTNNDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ArgsTemp():\n",
    "    def __init__(self, hidden_size, depth, device):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.depth = depth\n",
    "        self.device = device\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        \n",
    "args = ArgsTemp(200,3, device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(args.depth)\n",
    "\n",
    "dataset = JTNNDataset(data='valid', vocab='vocab', training=True, intermediates=True)\n",
    "vocab = dataset.vocab\n",
    "\n",
    "dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=10,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        collate_fn=JTNNCollator(vocab, True, intermediates=True),\n",
    "        drop_last=True,\n",
    "        worker_init_fn=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(dataloader)\n",
    "batch = next(data_iter)\n",
    "#for key in batch.keys():\n",
    "    #print(\"{}: {}\".format(key, batch[key]))\n",
    "mol_tree = batch['mol_trees'][0]\n",
    "graph_batch = batch['mol_graph_batch']\n",
    "line_graph = graph_batch.line_graph(backtracking=False, shared=True)\n",
    "\n",
    "#mols = [Chem.MolFromSmiles(mg.smiles) for mg in batch]\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from utils.cuda import cuda, move_dgl_to_cuda\n",
    "#plt.subplot(121)\n",
    "#nx.draw(mol_tree.to_networkx(), with_labels=True)\n",
    "#plt.show()\n",
    "#plt.subplot(121)\n",
    "#nx.draw(line_graph.to_networkx(), with_labels=True)\n",
    "#plt.show()\n",
    "\n",
    "from rdkit.Chem import Draw\n",
    "#smile_img = Draw.MolToImage(Chem.MolFromSmiles(batch['smiles'][0]))\n",
    "#imshow(smile_img)\n",
    "#Draw.MolsToGridImage(mols[0:6],molsPerRow=3,subImgSize=(300,200),legends=smiles)\n",
    "\n",
    "def move_to_cuda(mol_batch):\n",
    "        for t in mol_batch['mol_trees']:\n",
    "            move_dgl_to_cuda(t)\n",
    "\n",
    "        move_dgl_to_cuda(mol_batch['mol_graph_batch'])\n",
    "        if 'cand_graph_batch' in mol_batch:\n",
    "            move_dgl_to_cuda(mol_batch['cand_graph_batch'])\n",
    "        if mol_batch.get('stereo_cand_graph_batch') is not None:\n",
    "            move_dgl_to_cuda(mol_batch['stereo_cand_graph_batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%matplotlib inline\n",
    "for i,img in enumerate(batch['smiles_img']):\n",
    "    fig, axs = plt.subplots(len(batch['smiles_img']))\n",
    "    fig.suptitle('Candidates')\n",
    "    axs[0].imshow(img)\n",
    "    plt.imsave('mol'+str(i)+'.png', np.array(img))\n",
    "    axs[1].imshow(batch['img_grid'][i])\n",
    "    plt.imsave('mol'+str(i)+'cands.png', np.array(batch['img_grid'][i]))\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from models.modules.jtgcn import DGLJTMPN\n",
    "from models.modules.jtnn_enc import DGLJTNNEncoder\n",
    "\n",
    "embedding = nn.Embedding(vocab.size(), args.hidden_size)\n",
    "mpn = GraphConvNet(args)\n",
    "jtmpn = DGLJTMPN(args.hidden_size, args.depth)\n",
    "jtenc = DGLJTNNEncoder(vocab, args.hidden_size, embedding)\n",
    "\n",
    "programmers = ['Alex','Nicole','Sara','Etienne','Chelsea','Jody','Marianne']\n",
    "\n",
    "base = datetime.datetime.today()\n",
    "dates = base - np.arange(180) * datetime.timedelta(days=1)\n",
    "z = np.random.poisson(size=(len(programmers), len(dates)))\n",
    "\n",
    "#_ = [next(data_iter) for _ in range(200)]\n",
    "#print(mpn(batch['mol_graph_batch'])[:1,0])\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.ion()\n",
    "#fig.show()\n",
    "#fig.tight_layout()\n",
    "#ax.clear()\n",
    "\n",
    "historical_t = None\n",
    "historical_j = None\n",
    "batch_size=5\n",
    "for i in tqdm(range(0,5)):\n",
    "    mol_batch = next(data_iter)\n",
    "    t = mpn(mol_batch['mol_graph_batch'])[:1].cpu().detach()\n",
    "    j_batch, j = jtenc(mol_batch['mol_trees'])\n",
    "    j = j[:1].cpu().detach()\n",
    "    if i == 0:\n",
    "        historical_t = t\n",
    "        historical_j = j\n",
    "    else:\n",
    "        historical_t = torch.cat((historical_t,t),axis=0)\n",
    "        historical_j = torch.cat((historical_j,j),axis=0)\n",
    "        \n",
    "plt.imshow(historical_t, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(historical_j, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 200\n",
    "latent_size = 72\n",
    "T_mean = nn.Linear(hidden_size, latent_size // 2)\n",
    "T_var = nn.Linear(hidden_size, latent_size // 2)\n",
    "G_mean = nn.Linear(hidden_size, latent_size // 2)\n",
    "G_var = nn.Linear(hidden_size, latent_size // 2)\n",
    "\n",
    "def sample(tree_vec, mol_vec, e1=None, e2=None):\n",
    "        tree_mean = T_mean(tree_vec)\n",
    "        tree_log_var = -torch.abs(T_var(tree_vec))\n",
    "        mol_mean = G_mean(mol_vec)\n",
    "        mol_log_var = -torch.abs(G_var(mol_vec))\n",
    "\n",
    "        epsilon = cuda(torch.randn(*tree_mean.shape)) if e1 is None else e1\n",
    "        tree_vec = tree_mean + torch.exp(tree_log_var / 2) * epsilon\n",
    "        epsilon = cuda(torch.randn(*mol_mean.shape)) if e2 is None else e2\n",
    "        mol_vec = mol_mean + torch.exp(mol_log_var / 2) * epsilon\n",
    "\n",
    "        z_mean = torch.cat([tree_mean, mol_mean], 0)\n",
    "        z_log_var = torch.cat([tree_log_var, mol_log_var], 0)\n",
    "\n",
    "        return tree_vec, mol_vec, z_mean, z_log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(batch_size):\n",
    "    tree_vec, mol_vec, z_mean, z_log_var = sample(historical_j[i], historical_t[i],None,None)\n",
    "    print(-0.5 * torch.sum(1.0 + z_log_var - z_mean * z_mean - torch.exp(z_log_var)) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env] *",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}